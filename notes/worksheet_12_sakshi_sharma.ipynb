{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worksheet 12\n",
    "\n",
    "### Topics\n",
    "\n",
    "- Naive Bayes\n",
    "- Model Evaluation\n",
    "\n",
    "### Naive Bayes\n",
    "\n",
    "| Attribute A | Attribute B | Attribute C | Class |\n",
    "|-------------|-------------|-------------|-------|\n",
    "| Yes         | Single      | High        | No    |\n",
    "| No          | Married     | Mid         | No    |\n",
    "| No          | Single      | Low         | No    |\n",
    "| Yes         | Married     | High        | No    |\n",
    "| No          | Divorced    | Mid         | Yes   |\n",
    "| No          | Married     | Low         | No    |\n",
    "| Yes         | Divorced    | High        | No    |\n",
    "| No          | Single      | Mid         | Yes   |\n",
    "| No          | Married     | Low         | No    |\n",
    "| No          | Single      | Mid         | Yes   |\n",
    "\n",
    "a) Compute the following probabilities:\n",
    "\n",
    "- P(Attribute A = Yes | Class = No)\n",
    "- P(Attribute B = Divorced | Class = Yes)\n",
    "- P(Attribute C = High | Class = No)\n",
    "- P(Attribute C = Mid | Class = Yes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- P(Attribute A = Yes | Class = No) - 3/7\n",
    "- P(Attribute B = Divorced | Class = Yes) - 1/3\n",
    "- P(Attribute C = High | Class = No) - 3/7\n",
    "- P(Attribute C = Mid | Class = Yes) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Classify the following unseen records:\n",
    "\n",
    "- (Yes, Married, Mid)\n",
    "- (No, Divorced, High)\n",
    "- (No, Single, High)\n",
    "- (No, Divorced, Low)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (Yes, Married, Mid) - P(Yes) * P(Yes | C= Y) * P(Married | C=Y) * P(Mid | C=Y) vs P(No) * P(Yes | C= N) * P(Married | C=N) * P(Mid | C=N) => No\n",
    "- (No, Divorced, High) => No\n",
    "- (No, Single, High) => No\n",
    "- (No, Divorced, Low) => No"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation\n",
    "\n",
    "a) Write a function to generate the confusion matrix for a list of actual classes and a list of predicted classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4. 3.]\n",
      " [1. 2.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "actual_class = [\"Yes\", \"No\", \"No\", \"Yes\", \"No\", \"No\", \"Yes\", \"No\", \"No\", \"No\"]\n",
    "predicted_class = [\"Yes\", \"No\", \"Yes\", \"No\", \"No\", \"No\", \"Yes\", \"Yes\", \"Yes\", \"No\"]\n",
    "\n",
    "def confusion_matrix_calculation(actual, predicted):\n",
    "    classes = np.unique(actual)\n",
    "    # Initialize the confusion matrix as a 2D array of zeros\n",
    "    matrix = np.zeros((len(classes), len(classes)))\n",
    "    # For each pair of actual and predicted classes, increment the corresponding cell in the matrix\n",
    "    for i in range(len(actual)):\n",
    "        true_idx = np.where(classes == actual[i])[0][0]\n",
    "        pred_idx = np.where(classes == predicted[i])[0][0]\n",
    "        matrix[true_idx, pred_idx] += 1\n",
    "    return matrix\n",
    "\n",
    "print(confusion_matrix_calculation(actual_class, predicted_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Assume you have the following Cost Matrix:\n",
    "\n",
    "|            | predicted = Y | predicted = N |\n",
    "|------------|---------------|---------------|\n",
    "| actual = Y |       -1      |       5       |\n",
    "| actual = N |        10     |       0       |\n",
    "\n",
    "What is the cost of the above classification?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    }
   ],
   "source": [
    "cost_matrix = np.array([[-1, 5], [10, 0]])\n",
    "confusion_matrix = np.array([[4, 3], [1, 2]])\n",
    "#print(confusion_matrix * cost_matrix)\n",
    "cost = np.sum(confusion_matrix * cost_matrix)\n",
    "print(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Write a function that takes in the actual values, the predictions, and a cost matrix and outputs a cost. Test it on the above example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_score(act,pred,ct_matrix):\n",
    "    conf_matrix=confusion_matrix_calculation(act,pred)\n",
    "    cost = np.sum(conf_matrix * ct_matrix)\n",
    "    return cost\n",
    "get_score(actual_class,predicted_class,cost_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) What is the difference between a testing set and a validation set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both testing set and validation set are used to evaluate the performance of a machine learning model, but they serve different purposes.\n",
    "\n",
    "A training set is used to train the model. However, the model may overfit to the training data, i.e., it may memorize the training examples and not generalize well to new data.\n",
    "\n",
    "To address this issue, a portion of the training data is set aside as a validation set. The model is evaluated on the validation set during training to check if it is overfitting. The model's hyperparameters (e.g., the learning rate, regularization parameter) can be tuned based on the validation set performance.\n",
    "\n",
    "Once the model is trained and its hyperparameters are tuned, it is evaluated on a testing set to estimate its performance on unseen data. The testing set is independent of the training and validation sets and should not be used for any part of the model development process.\n",
    "\n",
    "So a validation set is used during training to monitor the model's performance and tune its hyperparameters, while a testing set is used after the model is fully developed and tuned to evaluate its performance on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) What are some things you can do to handle the case where you have a highly imbalanced dataset (i.e. there are way more of one class than another). Describe both how you can provide better visibility into the failures of the model and how you can set your model training up for success."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use techniques like bagging and boosting to train the data. Bagging involves training multiple models on different subsets of the dataset and averaging their predictions to reduce variance, while boosting involves training multiple models sequentially, with each subsequent model focusing on the misclassified examples of the previous model. These techniques can help improve the generalization of the model and reduce bias towards the majority class.\n",
    "\n",
    "To provide better visibility into the failures of the model, it's important to evaluate the model on both the overall accuracy and the per-class precision, recall, and F1 score. The confusion matrix can also be used to examine the distribution of correct and incorrect predictions across the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
